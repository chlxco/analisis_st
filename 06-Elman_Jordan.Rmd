# Modelos de Redes Neuronales Recurrentes

## Elman


### Carga de Datos
Para empezar el ejercicio, vamos a cargar nuevamente nuestros datos fuente. Esto con el fin de evitar cualquier transformacion anterior que pueda distorsionar la serie de tiempo original.

```{r}
library(forecast)
library(timsac)
library(ggplot2)
library(changepoint)
library(readxl)
library(RSNNS)
library(quantmod)


datos <- read_excel("./fuente/BASE_Clientes.xlsx")
datos
# Cambio el tipo de dato de la columna temporal(Periodo)
datos$Periodo <- as.Date(paste0(datos$Periodo, "-01"))

# Consolido el df en funcion de la variable de interes (Saldo)
datos <- aggregate(Saldo ~ Periodo, data = datos, sum)

# Genero mi objeto ts para el analisis
indice.ts <- ts(datos$Saldo, start = c(2018,1), frequency = 12)
indice.ts
```


### Creacion de la TS normalizada 

Una vez hecho esto, convierto mis datos a una time series (Z). Como estaremos trabajando con Redes Neuronales Recurrentes, normalizaremos la serie para que sus datos fluctuen entre 0 y 1.

```{r}
Z <- as.ts(indice.ts,F)
S <- (Z-min(Z))/(max(Z)-min(Z))
plot(S)

```

### Division de la serie.

Ahora dividiremos el el numero de filas totales para trabajar con nuestros sets de entrenamiento y testing. 

```{r}
lineas_totales <-length(S)
t_train <- round(lineas_totales*0.75, digits=0)
l_train <- 0:(t_train-1) 
t_test <- (t_train):lineas_totales
t_test

```
### Creacion de nodos.

Ahora crearemos un df con los nodos que adelantaran un valor en el futuro

```{r}
y <- as.zoo(S)
x1 <- Lag(y, k = 1)
x2 <- Lag(y, k = 2)
x3 <- Lag(y, k = 3)
x4 <- Lag(y, k = 4)
x5 <- Lag(y, k = 5)
x6 <- Lag(y, k = 6)
x7 <- Lag(y, k = 7)
x8 <- Lag(y, k = 8)
x9 <- Lag(y, k = 9)
x10 <- Lag(y, k = 10)
x11 <- Lag(y, k = 11)
x12 <- Lag(y, k = 12)
slogN <- cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12)
# Elimenemos los valores desplazados
slogN <- slogN[-(1:12),]
```

Acto seguido, especificaremos los inputs y outputs de la red

```{r}
inputs <- slogN[,2:13]
outputs <- slogN[,1]

```

### Entrenamiento del modelo Elman

Con la informaion en su lugar, procedamos a crear la red de Elman. Despues de varias pruebas, el numero de neuronas y profundidad queda en 110 y 5 respectivamente. 

```{r}
set.seed(42)
fit <- fit<-elman(inputs[t_train],outputs[t_train],size=c(110,5),learnFuncParams=c(0.1),maxit=100000)
```

Veamos como evoluciona el error

```{r}
plotIterativeError(fit, main = "Error Iterativo para neuronas 110,5")
```
Como podemos observar, el error converge extremadamente rapido. 



Ahora procederemos a hacer la la prediccion con el resto de terminos de la serie:

```{r}
y <- as.vector(outputs[-t_test])
plot(y,type="l")
pred <- predict(fit, inputs[-t_test])
lines(pred,col = "red")
```
### Prediccion

Procedemos a hacer las predicciones con nuestra red
```{r}
predictions <- predict(fit,inputs[-t_train])
```

Desnormalizamos datos

```{r}
mod_elman <- predictions*(max(Z)-min(Z))+min(Z)
mod_elman
```

veamos los valores

```{r}
x <- 1:(lineas_totales+length(mod_elman))
y <- c(as.vector(Z),mod_elman)
plot(x[1:lineas_totales], y[1:lineas_totales],col = "blue", type="l")
lines( x[(lineas_totales):length(x)], y[(lineas_totales):length(x)], col="red")
```

## Jordan

### Entrenamiento del modelo Jordan

Como ya tenemos la tsnormalizada (S) y dividida entre training y testing, procedemos a entrenar el algoritmo con Jordan: 

```{r}
fit<-jordan(inputs[t_train],
    outputs[t_train],
    size=16,
    learnFuncParams=c(0.01),
    maxit=100000)
```

### Error Iterativo

Ploteamos el error iterativo de 16 neuronas:
```{r}
plotIterativeError(fit, main = "Error iterativo para 16 neuronas")
```


Veamos ahora como se comporta el error: 

```{r}
y <- as.vector(outputs[-t_test])
plot(y,type="l")
pred <- predict(fit, inputs[-t_test])
lines(pred,col = "red")
```
Procedemos con la prediccion
```{r}
predictions <- predict(fit,inputs[-t_train])
mod_jordan <- predictions*(max(Z)-min(Z))+min(Z)
mod_jordan
```

### Resultados de la prediccion

Ahora veamoslo en la grafica

```{r}
x <- 1:(lineas_totales+length(mod_jordan))
y <- c(as.vector(Z),mod_jordan)
plot(x[1:lineas_totales], y[1:lineas_totales],col = "blue", type="l")
lines( x[(lineas_totales):length(x)], y[(lineas_totales):length(x)], col="red")
```











